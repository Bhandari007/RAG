{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Foundations and basic implementation"
      ],
      "metadata": {
        "id": "9FYRK9jUgKzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment"
      ],
      "metadata": {
        "id": "2CgnpM2kh3iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"xAI_KEY\"] = \"xai-qQ03B16VE4h2habRcFj30QcoQrNUOtiN81gGxtgiKmtf2NWgHuvThZRnV2h1hEV85o82gX2DjrA7ixbg\""
      ],
      "metadata": {
        "id": "igGHwqcRh98X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Generator"
      ],
      "metadata": {
        "id": "9J6ncVPviP1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "uAwRqfhNiWS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_llm_with_full_text(itext):\n",
        "  # Set the URL and headers\n",
        "  url = \"https://api.x.ai/v1/chat/completions\"\n",
        "  headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {os.environ['xAI_KEY']}\"\n",
        "  }\n",
        "\n",
        "  data = {\n",
        "      \"messages\": [\n",
        "          {\n",
        "              \"role\":\"system\",\n",
        "              \"content\": \"You're a test assistant\"\n",
        "          },\n",
        "          {\n",
        "              \"role\":\"user\",\n",
        "              \"content\": itext\n",
        "          }\n",
        "      ],\n",
        "      \"model\": \"grok-beta\",\n",
        "      \"stream\": False,\n",
        "      \"temprature\": 0\n",
        "  }\n",
        "\n",
        "  # Send the POST request\n",
        "  response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    # Convert the response to a dictionary\n",
        "    response_data = response.json()\n",
        "    content = response_data[\"choices\"][0]['message']['content']\n",
        "  else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "  return content"
      ],
      "metadata": {
        "id": "Tzu1OeK2iyYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatted response"
      ],
      "metadata": {
        "id": "Sc9pO-kikLKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "def print_formatted_response(response):\n",
        "  # Define the width for wrapping the text\n",
        "  wrapper = textwrap.TextWrapper(width=80)\n",
        "  wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "  # Printthe formatted response with a header and footer\n",
        "  print(\"Response:\")\n",
        "  print(\"---------------------\")\n",
        "  print(wrapped_text)\n",
        "  print(\"---------------------\\n\")"
      ],
      "metadata": {
        "id": "5E9iR4e2kPfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. The Data"
      ],
      "metadata": {
        "id": "Sg707hubkmB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_records = [\n",
        "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
        "    \"It innovatively combines the capabilities of neural network-based language models with retrieval systems to enhance the generation of text, making it more accurate, informative, and contextually relevant.\",\n",
        "    \"This methodology leverages the strengths of both generative and retrieval architectures to tackle complex tasks that require not only linguistic fluency but also factual correctness and depth of knowledge.\",\n",
        "    \"At the core of Retrieval Augmented Generation (RAG) is a generative model, typically a transformer-based neural network, similar to those used in models like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers).\",\n",
        "    \"This component is responsible for producing coherent and contextually appropriate language outputs based on a mixture of input prompts and additional information fetched by the retrieval component.\",\n",
        "    \"Complementing the language model is the retrieval system, which is usually built on a database of documents or a corpus of texts.\",\n",
        "    \"This system uses techniques from information retrieval to find and fetch documents that are relevant to the input query or prompt.\",\n",
        "    \"The mechanism of relevance determination can range from simple keyword matching to more complex semantic search algorithms which interpret the meaning behind the query to find the best matches.\",\n",
        "    \"This component merges the outputs from the language model and the retrieval system.\",\n",
        "    \"It effectively synthesizes the raw data fetched by the retrieval system into the generative process of the language model.\",\n",
        "    \"The integrator ensures that the information from the retrieval system is seamlessly incorporated into the final text output, enhancing the model's ability to generate responses that are not only fluent and grammatically correct but also rich in factual details and context-specific nuances.\",\n",
        "    \"When a query or prompt is received, the system first processes it to understand the requirement or the context.\",\n",
        "    \"Based on the processed query, the retrieval system searches through its database to find relevant documents or information snippets.\",\n",
        "    \"This retrieval is guided by the similarity of content in the documents to the query, which can be determined through various techniques like vector embeddings or semantic similarity measures.\",\n",
        "    \"The retrieved documents are then fed into the language model.\",\n",
        "    \"In some implementations, this integration happens at the token level, where the model can access and incorporate specific pieces of information from the retrieved texts dynamically as it generates each part of the response.\",\n",
        "    \"The language model, now augmented with direct access to retrieved information, generates a response.\",\n",
        "    \"This response is not only influenced by the training of the model but also by the specific facts and details contained in the retrieved documents, making it more tailored and accurate.\",\n",
        "    \"By directly incorporating information from external sources, Retrieval Augmented Generation (RAG) models can produce responses that are more factual and relevant to the given query.\",\n",
        "    \"This is particularly useful in domains like medical advice, technical support, and other areas where precision and up-to-date knowledge are crucial.\",\n",
        "    \"Retrieval Augmented Generation (RAG) systems can dynamically adapt to new information since they retrieve data in real-time from their databases.\",\n",
        "    \"This allows them to remain current with the latest knowledge and trends without needing frequent retraining.\",\n",
        "    \"With access to a wide range of documents, Retrieval Augmented Generation (RAG) systems can provide detailed and nuanced answers that a standalone language model might not be capable of generating based solely on its pre-trained knowledge.\",\n",
        "    \"While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\",\n",
        "    \"These include the complexity of integrating retrieval and generation systems, the computational overhead associated with real-time data retrieval, and the need for maintaining a large, up-to-date, and high-quality database of retrievable texts.\",\n",
        "    \"Furthermore, ensuring the relevance and accuracy of the retrieved information remains a significant challenge, as does managing the potential for introducing biases or errors from the external sources.\",\n",
        "    \"In summary, Retrieval Augmented Generation represents a significant advancement in the field of artificial intelligence, merging the best of retrieval-based and generative technologies to create systems that not only understand and generate natural language but also deeply comprehend and utilize the vast amounts of information available in textual form.\",\n",
        "    \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
        "]"
      ],
      "metadata": {
        "id": "YAFaRFRelR62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "paragraph = ' '.join(db_records)\n",
        "wrapped_text = textwrap.fill(paragraph, width=80)\n",
        "print(wrapped_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMuK5XqglU40",
        "outputId": "3ffbbbe1-b668-44f3-a7ca-d019b156d895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach\n",
            "in the field of artificial intelligence, particularly within the realm of\n",
            "natural language processing (NLP). It innovatively combines the capabilities of\n",
            "neural network-based language models with retrieval systems to enhance the\n",
            "generation of text, making it more accurate, informative, and contextually\n",
            "relevant. This methodology leverages the strengths of both generative and\n",
            "retrieval architectures to tackle complex tasks that require not only linguistic\n",
            "fluency but also factual correctness and depth of knowledge. At the core of\n",
            "Retrieval Augmented Generation (RAG) is a generative model, typically a\n",
            "transformer-based neural network, similar to those used in models like GPT\n",
            "(Generative Pre-trained Transformer) or BERT (Bidirectional Encoder\n",
            "Representations from Transformers). This component is responsible for producing\n",
            "coherent and contextually appropriate language outputs based on a mixture of\n",
            "input prompts and additional information fetched by the retrieval component.\n",
            "Complementing the language model is the retrieval system, which is usually built\n",
            "on a database of documents or a corpus of texts. This system uses techniques\n",
            "from information retrieval to find and fetch documents that are relevant to the\n",
            "input query or prompt. The mechanism of relevance determination can range from\n",
            "simple keyword matching to more complex semantic search algorithms which\n",
            "interpret the meaning behind the query to find the best matches. This component\n",
            "merges the outputs from the language model and the retrieval system. It\n",
            "effectively synthesizes the raw data fetched by the retrieval system into the\n",
            "generative process of the language model. The integrator ensures that the\n",
            "information from the retrieval system is seamlessly incorporated into the final\n",
            "text output, enhancing the model's ability to generate responses that are not\n",
            "only fluent and grammatically correct but also rich in factual details and\n",
            "context-specific nuances. When a query or prompt is received, the system first\n",
            "processes it to understand the requirement or the context. Based on the\n",
            "processed query, the retrieval system searches through its database to find\n",
            "relevant documents or information snippets. This retrieval is guided by the\n",
            "similarity of content in the documents to the query, which can be determined\n",
            "through various techniques like vector embeddings or semantic similarity\n",
            "measures. The retrieved documents are then fed into the language model. In some\n",
            "implementations, this integration happens at the token level, where the model\n",
            "can access and incorporate specific pieces of information from the retrieved\n",
            "texts dynamically as it generates each part of the response. The language model,\n",
            "now augmented with direct access to retrieved information, generates a response.\n",
            "This response is not only influenced by the training of the model but also by\n",
            "the specific facts and details contained in the retrieved documents, making it\n",
            "more tailored and accurate. By directly incorporating information from external\n",
            "sources, Retrieval Augmented Generation (RAG) models can produce responses that\n",
            "are more factual and relevant to the given query. This is particularly useful in\n",
            "domains like medical advice, technical support, and other areas where precision\n",
            "and up-to-date knowledge are crucial. Retrieval Augmented Generation (RAG)\n",
            "systems can dynamically adapt to new information since they retrieve data in\n",
            "real-time from their databases. This allows them to remain current with the\n",
            "latest knowledge and trends without needing frequent retraining. With access to\n",
            "a wide range of documents, Retrieval Augmented Generation (RAG) systems can\n",
            "provide detailed and nuanced answers that a standalone language model might not\n",
            "be capable of generating based solely on its pre-trained knowledge. While\n",
            "Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes\n",
            "with its challenges. These include the complexity of integrating retrieval and\n",
            "generation systems, the computational overhead associated with real-time data\n",
            "retrieval, and the need for maintaining a large, up-to-date, and high-quality\n",
            "database of retrievable texts. Furthermore, ensuring the relevance and accuracy\n",
            "of the retrieved information remains a significant challenge, as does managing\n",
            "the potential for introducing biases or errors from the external sources. In\n",
            "summary, Retrieval Augmented Generation represents a significant advancement in\n",
            "the field of artificial intelligence, merging the best of retrieval-based and\n",
            "generative technologies to create systems that not only understand and generate\n",
            "natural language but also deeply comprehend and utilize the vast amounts of\n",
            "information available in textual form. A RAG vector store is a database or\n",
            "dataset that contains vectorized data points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. The Query"
      ],
      "metadata": {
        "id": "gQogEIWEmDAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what store offers rags?\""
      ],
      "metadata": {
        "id": "0Gtaj0V2mNhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation without augmentation"
      ],
      "metadata": {
        "id": "7mcVijdjnBtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5SjAj5EmcAC",
        "outputId": "431211c3-7e5a-4f10-9e7b-b2cb5fdeac36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "Many stores offer rags, depending on what you're looking for:  1. **Hardware\n",
            "Stores** - Home Depot, Lowe's, or Ace Hardware usually have cleaning rags,\n",
            "microfiber cloths, and shop rags for various uses.  2. **Big Box Retailers** -\n",
            "Walmart, Target, and similar stores carry rags in their cleaning or automotive\n",
            "sections.  3. **Grocery Stores** - Some supermarkets have a cleaning or\n",
            "household section where you might find rags.  4. **Dollar Stores** - Dollar\n",
            "Tree, Family Dollar, or similar discount stores often have rags at a very\n",
            "affordable price.  5. **Automotive Stores** - Stores like AutoZone, Advance Auto\n",
            "Parts, or O'Reilly Auto Parts carry shop rags which are great for auto detailing\n",
            "or general cleaning.  6. **Online Retailers** - Amazon, eBay, or even specialty\n",
            "sites like The Rag Company for more specialized cleaning cloths.  7. **Thrift\n",
            "Stores** - Goodwill or Salvation Army might have old t-shirts or other fabric\n",
            "items that can be repurposed into rags.  8. **Home Goods Stores** - Bed Bath &\n",
            "Beyond, IKEA, or TJ Maxx might have designer or high-quality cloths for\n",
            "cleaning.  9. **Specialty Cleaning Supply Stores** - Some places focus solely on\n",
            "cleaning supplies where you can find a variety of rags and cleaning cloths.\n",
            "Remember to look for rags that are appropriate for your intended use, whether\n",
            "it's for dusting, polishing, detailing, or general cleaning. Also, consider the\n",
            "material (like microfiber for electronics, cotton for general use, etc.) and\n",
            "whether you need disposable or reusable rags.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Adavnce techinques and evaluation"
      ],
      "metadata": {
        "id": "gXI_dm40mono"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Retrieval metrics"
      ],
      "metadata": {
        "id": "s0ozUUP0nQwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "9jj3XCqsn2GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_similarity(text1, text2):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "      stop_words='english',\n",
        "      use_idf = True,\n",
        "      norm='l2',\n",
        "      ngram_range=(1,2),\n",
        "      sublinear_tf=True,\n",
        "      analyzer='word'\n",
        "  )\n",
        "\n",
        "  tfidf = vectorizer.fit_transform([text1, text2])\n",
        "  similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "  return similarity[0][0]"
      ],
      "metadata": {
        "id": "ACILCEAtoP3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhanced similarity"
      ],
      "metadata": {
        "id": "4LeZEoW-o_gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1B2LxBJpafW",
        "outputId": "786d3222-b10e-4563-b2d4-a9e7da8bc9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Jej1vaeepxn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms(word):\n",
        "  synonyms = set()\n",
        "  for syn in wordnet.synsets(word):\n",
        "    for lemma in syn.lemmas():\n",
        "      synonyms.add(lemma.name())\n",
        "  return synonyms"
      ],
      "metadata": {
        "id": "-A4tcPABp83P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  doc = nlp(text.lower())\n",
        "  lemmatized_words = []\n",
        "  for token in doc:\n",
        "    if token.is_stop or token.is_punct:\n",
        "      continue\n",
        "    lemmatized_words.append(token.lemma_)\n",
        "  return lemmatized_words"
      ],
      "metadata": {
        "id": "75tpzCD9qZ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_with_synonyms(words):\n",
        "  expanded_words = words.copy()\n",
        "  for word in words:\n",
        "    expanded_words.extend(get_synonyms(word))\n",
        "  return expanded_words"
      ],
      "metadata": {
        "id": "6GEy7iQwqpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_enhanced_similarity(text1, text2):\n",
        "  words1 = preprocess_text(text1)\n",
        "  words2 = preprocess_text(text2)\n",
        "\n",
        "  expanded_words1 = expand_with_synonyms(words1)\n",
        "  expanded_words2 = expand_with_synonyms(words2)\n",
        "\n",
        "  freq1 = Counter(expanded_words1)\n",
        "  freq2 = Counter(expanded_words2)\n",
        "\n",
        "  unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
        "\n",
        "  vector1 = [freq1[word] for word in unique_words]\n",
        "  vector2 = [freq2[word] for word in unique_words]\n",
        "\n",
        "  vector1 = np.array(vector1)\n",
        "  vector2 = np.array(vector2)\n",
        "\n",
        "\n",
        "  cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "  return cosine_similarity\n"
      ],
      "metadata": {
        "id": "zKfE9U7jq07u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. NaÃ¯ve RAG"
      ],
      "metadata": {
        "id": "WoYfHfmvrXrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keyword search and matching"
      ],
      "metadata": {
        "id": "f8k5cJnLrek_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_match_keyword_search(query, db_records):\n",
        "  best_score = 0\n",
        "  best_record = None\n",
        "\n",
        "  # Split the query into individual keywords\n",
        "  query_keywords = set(query.lower().split())\n",
        "\n",
        "  # Iterate through each record in db_records\n",
        "  for record in db_records:\n",
        "    # Split the record into keywords\n",
        "    record_keywords = set(record.lower().split())\n",
        "\n",
        "    # Calculate the number of common keywords\n",
        "    common_keywords = query_keywords.intersection(record_keywords)\n",
        "    current_score = len(common_keywords)\n",
        "\n",
        "    # Update the best score and record if the current score is higher\n",
        "    if current_score > best_score:\n",
        "      best_score = current_score\n",
        "      best_record = record\n",
        "\n",
        "  return best_score, best_record\n"
      ],
      "metadata": {
        "id": "6g7j3EFIncjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_keyword_score, best_matching_record = find_best_match_keyword_search(\n",
        "    query,\n",
        "    db_records\n",
        ")\n",
        "print(f\"Best Keyword Score: {best_keyword_score}\")\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM4uMSCTnyr8",
        "outputId": "81a20d57-163f-48dd-e301-f6b9dfd42c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Keyword Score: 1\n",
            "Response:\n",
            "---------------------\n",
            "While Retrieval Augmented Generation (RAG) offers substantial benefits, it also\n",
            "comes with its challenges.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "nioZI9AOone-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity\n",
        "score = calculate_cosine_similarity(query, best_matching_record)\n",
        "print(f\"Cosine Similarity Score: {score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUsRdZO3o7MC",
        "outputId": "293366f3-54a1-417c-ec10-c6a2618130b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Score: 0.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enchanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOaSOhDKo-1V",
        "outputId": "8ae7e4bd-b5a0-4950-9a66-75290450f82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what store offers rags? :  While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\n",
            "Enhanced Similarity Score: 0.641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmented input"
      ],
      "metadata": {
        "id": "npPuQQt4pTyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_input = query+\": \"+ best_matching_record"
      ],
      "metadata": {
        "id": "Xn4vgWzprEjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obX5vgpKrMMm",
        "outputId": "e3fbcfab-94e4-477b-9729-5ca96104a9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "what store offers rags?: While Retrieval Augmented Generation (RAG) offers\n",
            "substantial benefits, it also comes with its challenges.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "q7D1PxqCrP9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40UkaZczriwl",
        "outputId": "740744d0-4001-4bb0-bd04-48aa0ec36b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "Here are some of the key **challenges** associated with implementing Retrieval\n",
            "Augmented Generation (RAG):  1. **Quality and Relevance of Retrieved\n",
            "Information**:    - Ensuring the information retrieved is not only relevant but\n",
            "also of high quality can be challenging. Irrelevant or low-quality data can lead\n",
            "to poor model outputs.  2. **Latency**:    - The process of retrieving documents\n",
            "and then generating responses can introduce latency, especially if the retrieval\n",
            "system involves complex queries or searches over large datasets.  3.\n",
            "**Scalability**:    - Scaling the retrieval system to handle large volumes of\n",
            "documents or queries efficiently requires significant computational resources\n",
            "and sophisticated indexing and search algorithms.  4. **Indexing and Search\n",
            "Accuracy**:    - Effective RAG systems require robust indexing of documents.\n",
            "Inaccuracies in indexing or search algorithms can result in retrieving incorrect\n",
            "or outdated information.  5. **Data Integration and Consistency**:    -\n",
            "Integrating RAG with existing data systems while maintaining consistency across\n",
            "different data sources and formats can be complex.  6. **Privacy and Security\n",
            "Concerns**:    - Since RAG often involves accessing external documents or\n",
            "databases, there are concerns about data privacy, security, and compliance with\n",
            "regulations like GDPR.  7. **Model Overfitting**:    - There's a risk of the\n",
            "model overfitting to the retrieved documents if not managed properly, which\n",
            "could limit the model's generalization capability.  8. **Cost**:    - The\n",
            "additional computational overhead for retrieval can increase costs, particularly\n",
            "when using cloud services or large databases.  9. **Complexity in Training and\n",
            "Tuning**:    - Training models to effectively use retrieved information adds\n",
            "another layer of complexity, requiring careful tuning of how the model processes\n",
            "and incorporates this data.  10. **Contextual Understanding**:     - The model\n",
            "must understand the context in which the retrieved information should be used,\n",
            "which isn't always straightforward, especially with ambiguous queries.  11.\n",
            "**Handling Document Updates**:     - Keeping the retrieval system up-to-date\n",
            "with the latest documents or changes in existing documents poses logistical\n",
            "challenges.  12. **User Experience**:     - Ensuring that the user experience\n",
            "remains seamless despite the underlying complexity of RAG systems is crucial.\n",
            "Users might not understand why responses are slower or why certain information\n",
            "is included.  Addressing these challenges requires a combination of advancements\n",
            "in natural language processing, improvements in retrieval algorithms, better\n",
            "data management practices, and thoughtful system design. Each challenge presents\n",
            "an opportunity for innovation in how we develop and deploy AI systems that\n",
            "leverage external knowledge bases.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced RAG"
      ],
      "metadata": {
        "id": "5vkNmr_RrtSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Search"
      ],
      "metadata": {
        "id": "9CWcOwjHs29e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fjrAKCeE1syb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Search Function\n",
        "def find_best_match(text_input, records):\n",
        "  best_score = 0\n",
        "  best_record = None\n",
        "  for record in records:\n",
        "    current_score = calculate_cosine_similarity(text_input, record)\n",
        "    if current_score > best_score:\n",
        "      best_score = current_score\n",
        "      best_record = record\n",
        "  return best_score, best_record"
      ],
      "metadata": {
        "id": "PVDPrVo607-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_similarity_score, best_matrching_record = find_best_match(\n",
        "    query,\n",
        "    db_records\n",
        ")\n",
        "print(f\"Best Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matrching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUVJahZN1Tg9",
        "outputId": "df56dd4d-18d7-4b9c-d441-fe309841aef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Similarity Score: 0.059\n",
            "Response:\n",
            "---------------------\n",
            "While Retrieval Augmented Generation (RAG) offers substantial benefits, it also\n",
            "comes with its challenges.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrics\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2yqZU5U1cLs",
        "outputId": "1a4d4aea-742b-4b60-83a4-84392bde458d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enchanced Similarity\n",
        "respsone = best_matching_record\n",
        "print(query, \": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, best_matching_record)\n",
        "print(f\"Enhanced Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg0NHvZp1-ZD",
        "outputId": "2d865864-569f-4d94-bb2d-a2e45017e48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what store offers rags? :  While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\n",
            "Enhanced Similarity Score: 0.641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Augmented input\n",
        "augmented_input = query + \": \" + best_matching_record"
      ],
      "metadata": {
        "id": "QqtQANwy2Wlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqeJ73V62fFi",
        "outputId": "de30d248-8de4-4045-96fe-8adee0682f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "what store offers rags?: While Retrieval Augmented Generation (RAG) offers\n",
            "substantial benefits, it also comes with its challenges.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generation\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1r0Q5ax2hjM",
        "outputId": "a3a24a25-ecf9-4dcf-af78-f076d4ba1b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "While **Rags** might not directly relate to stores, if you're looking for places\n",
            "that might sell cleaning rags or rags for other uses, here are some options:  -\n",
            "**Hardware Stores**: Like Home Depot, Lowe's, or Ace Hardware where you can find\n",
            "cleaning rags or even cloths designed for specific tasks. - **Supermarkets**:\n",
            "Stores like Walmart, Target, or any local supermarket often have a section for\n",
            "household cleaning supplies, which includes rags or microfiber cloths. - **Auto\n",
            "Parts Stores**: If you're looking for shop rags or heavy-duty cleaning cloths,\n",
            "places like AutoZone, Advance Auto Parts, or O'Reilly Auto Parts could be\n",
            "useful. - **Thrift Stores**: Goodwill, Salvation Army, or other thrift stores\n",
            "might have old t-shirts or fabric that can be repurposed into rags. - **Online\n",
            "Retailers**: Amazon, eBay, or even specialized online stores for cleaning\n",
            "supplies or automotive products often offer a wide range of rag options.  If you\n",
            "were actually asking about Retrieval Augmented Generation (RAG) in AI, here's a\n",
            "brief overview:  **Benefits of RAG:** - **Enhanced Accuracy**: By retrieving\n",
            "relevant information, RAG can provide more accurate answers or responses\n",
            "tailored to the context of the query. - **Up-to-date Information**: RAG can\n",
            "incorporate the latest information, making the system more current than static\n",
            "models. - **Reduced Hallucinations**: Since RAG pulls from external data\n",
            "sources, it can reduce instances where the model generates incorrect or\n",
            "fabricated information.  **Challenges of RAG:** - **Complexity**: Integrating\n",
            "retrieval with generation adds layers of complexity in model design, training,\n",
            "and deployment. - **Latency**: Retrieval steps can add to the response time,\n",
            "which might be critical in real-time applications. - **Data Quality**: The\n",
            "effectiveness of RAG heavily depends on the quality and relevance of the data\n",
            "being retrieved. Poor data can lead to poor results. - **Scalability**: As the\n",
            "knowledge base grows, so does the challenge of efficiently indexing and\n",
            "retrieving relevant information. - **Privacy and Security**: Handling external\n",
            "data sources introduces concerns about data privacy and security, especially\n",
            "when dealing with sensitive information. - **Cost**: The need for continuous\n",
            "retrieval and potential storage of large datasets can increase operational\n",
            "costs.  If you have more specific questions about RAG or are looking for\n",
            "something else related to \"rags,\" please let me know!\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index-based search"
      ],
      "metadata": {
        "id": "Q82MnHXC2nMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Search Function\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_matrix = vectorizer.fit_transform(records)\n",
        "  return vectorizer, tfidf_matrix\n",
        "\n",
        "def find_best_match(query, vectorizer, tfidf_matrix):\n",
        "  query_vector = vectorizer.transform([query])\n",
        "  similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
        "  best_index = similarity_scores.argmax()\n",
        "  best_score = similarity_scores[0, best_index]\n",
        "  return best_score, best_index"
      ],
      "metadata": {
        "id": "7V3_Eu9x3G4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
        "best_similarity_score, best_matching_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
        "best_matching_record = db_records[best_matching_index]\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kdOAUVH3woX",
        "outputId": "bbf25480-07c3-4868-af32-7376089ca0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrics\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJIxOsPE39ca",
        "outputId": "1be9ab99-6c31-4ac8-db03-3192166216c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enchanced Similarity\n",
        "response = best_matching_record\n",
        "print(query, \": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity Score: {similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNUX8bL14dK3",
        "outputId": "36b6839f-30d7-412f-f6da-eb59cf198931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what store offers rags? :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity Score: 0.612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Extraction\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_matrix = vectorizer.fit_transform(records)\n",
        "\n",
        "  tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "  print(tfidf_df)\n",
        "  return vectorizer, tfidf_matrix\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTIK_Ul24iSC",
        "outputId": "fd81fb1c-d34b-4f70-cede-d300a8ba6485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ability    access  accuracy  accurate     adapt  additional  advancement  \\\n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "1   0.000000  0.000000  0.000000  0.216364  0.000000    0.000000     0.000000   \n",
            "2   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "3   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "4   0.000000  0.000000  0.000000  0.000000  0.000000    0.236479     0.000000   \n",
            "5   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "6   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "7   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "8   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "9   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "10  0.186734  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "11  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "12  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "13  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "14  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "15  0.000000  0.172624  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "16  0.000000  0.317970  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "17  0.000000  0.000000  0.000000  0.206861  0.000000    0.000000     0.000000   \n",
            "18  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "19  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "20  0.000000  0.000000  0.000000  0.000000  0.275802    0.000000     0.000000   \n",
            "21  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "22  0.000000  0.174772  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "23  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "24  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "25  0.000000  0.000000  0.228743  0.000000  0.000000    0.000000     0.000000   \n",
            "26  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.173327   \n",
            "27  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "\n",
            "      advice  algorithms    allows  ...    vector  vectorized      when  \\\n",
            "0   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "1   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "2   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "3   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "4   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "5   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "6   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "7   0.000000    0.220687  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "8   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "9   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "10  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "11  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.295573   \n",
            "12  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "13  0.000000    0.000000  0.000000  ...  0.200131     0.00000  0.000000   \n",
            "14  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "15  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "16  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "17  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "18  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "19  0.244401    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "20  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "21  0.000000    0.000000  0.291503  ...  0.000000     0.00000  0.000000   \n",
            "22  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "23  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "24  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "25  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "26  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "27  0.000000    0.000000  0.000000  ...  0.307719     0.34589  0.000000   \n",
            "\n",
            "       where     which    while     wide      with    within   without  \n",
            "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.260582  0.000000  \n",
            "1   0.000000  0.000000  0.00000  0.00000  0.160278  0.000000  0.000000  \n",
            "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "5   0.000000  0.247710  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "7   0.000000  0.179053  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "13  0.000000  0.182517  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "14  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "15  0.189283  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "16  0.000000  0.000000  0.00000  0.00000  0.258278  0.000000  0.000000  \n",
            "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "19  0.217430  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "21  0.000000  0.000000  0.00000  0.00000  0.192110  0.000000  0.291503  \n",
            "22  0.000000  0.000000  0.00000  0.21541  0.141963  0.000000  0.000000  \n",
            "23  0.000000  0.000000  0.32932  0.00000  0.217033  0.000000  0.000000  \n",
            "24  0.000000  0.000000  0.00000  0.00000  0.134513  0.000000  0.000000  \n",
            "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "27  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[28 rows x 297 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Augmented input\n",
        "augmented_input = query+\": \"+best_matching_record"
      ],
      "metadata": {
        "id": "I_wFbdV84sFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYan_41s5aeG",
        "outputId": "f81d6209-8b43-40ed-e30d-f3b8ca5bd530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "what store offers rags?: A RAG vector store is a database or dataset that\n",
            "contains vectorized data points.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generation\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKZA2CC15dam",
        "outputId": "3ebd8c4e-88fa-45d0-f3c4-176c493ae116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "**Stores That Offer Rags:**  1. **Hardware Stores** - Like **Home Depot** or\n",
            "**Lowe's**, where rags are commonly sold for cleaning and workshop uses.  2.\n",
            "**Automotive Stores** - Such as **AutoZone** or **Advance Auto Parts**, where\n",
            "rags are useful for car maintenance and cleaning.  3. **General Retailers** -\n",
            "- **Walmart** and **Target** often have a cleaning supplies section where rags\n",
            "can be found.    - **Dollar Stores** like Dollar Tree, where you can find rags\n",
            "at a lower cost.  4. **Online Retailers:**    - **Amazon** - Offers a wide\n",
            "variety of rags from different brands and materials.    - **eBay** - For both\n",
            "new and second-hand rags, sometimes in bulk.  5. **Specialty Cleaning Supply\n",
            "Stores** - These might offer higher quality or specialized rags for industrial\n",
            "or professional cleaning needs.  6. **Thrift Stores** - Places like **Goodwill**\n",
            "or **Salvation Army** might have rags or cloths made from recycled materials.\n",
            "7. **Fabric Stores** - While not traditional for rags, stores like **Jo-Ann\n",
            "Fabric and Craft Stores** or **Hobby Lobby** might sell fabric that could be cut\n",
            "into rags.  8. **Home Goods Stores** - **Bed Bath & Beyond** (or what remains of\n",
            "it online), **IKEA**, or similar stores often carry cleaning rags or cloths.\n",
            "When buying rags, consider: - **Material**: Cotton is durable and absorbent,\n",
            "microfiber is good for dust and cleaning electronics. - **Quantity**: Whether\n",
            "you need a pack or a bulk amount. - **Intended Use**: Different types of rags\n",
            "might be suited for different tasks (e.g., automotive vs. home cleaning).\n",
            "Remember, some stores might not always carry rags, so it's good to call ahead or\n",
            "check online inventory if possible.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modular RAG"
      ],
      "metadata": {
        "id": "GqPFTklU5jka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ZCAAtv7_5zl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetrievalComponent:\n",
        "  def __init__(self, method='vector'):\n",
        "    self.method = method\n",
        "    if self.method == 'vector' or self.method == 'indexed':\n",
        "      self.vectorizer = TfidfVectorizer()\n",
        "      self.tfidf_matrix = None\n",
        "\n",
        "  def fit(self, records):\n",
        "    self.documents = records\n",
        "    if self.method == 'vector' or self.method == 'indexed':\n",
        "      self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
        "\n",
        "  def retrieve(self, query):\n",
        "    if self.method == 'keyword':\n",
        "      return self.keyword_search(query)\n",
        "    elif self.method == 'vector':\n",
        "      return self.vector_search(query)\n",
        "    elif self.method == 'indexed':\n",
        "      return self.indexed_search(query)\n",
        "\n",
        "\n",
        "  def keyword_search(self, query):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "    query_keywords = set(query.lower().split())\n",
        "    for index, doc in enumerate(self.documents):\n",
        "      doc_keywords = set(doc.lower().split())\n",
        "      common_keywords = query_keywords.intersection(doc_keywords)\n",
        "      current_score = len(common_keywords)\n",
        "      if current_score > best_score:\n",
        "        best_score = current_score\n",
        "        best_record = doc\n",
        "    return best_record\n",
        "\n",
        "  def vector_search(self, query):\n",
        "    query_tfidf = self.vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "    best_index = similarities.argmax()\n",
        "    return self.documents[best_index]\n",
        "\n",
        "  def indexed_search(self, query):\n",
        "    query_tfidf = self.vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
        "    best_index = similarities.argmax()\n",
        "    return self.documents[best_index]"
      ],
      "metadata": {
        "id": "kb3N-tcTd1o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Modular RAG Strategies\n",
        "retrieval = RetrievalComponent(method='vector')\n",
        "retrieval.fit(db_records)\n",
        "best_matching_record = retrieval.retrieve(query)\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLo99o1Mggp8",
        "outputId": "317ef08b-536a-4af6-e979-ef17437a8cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metrics\n",
        "# Cosine Similarity\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwp4RqxMgrdC",
        "outputId": "e4aee1bb-e9dd-4be8-fdf2-3eb8d9460b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.245\n",
            "Response:\n",
            "---------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Similarity\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(\"Enhanced Similarity:\", similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9rZsg9kgwnM",
        "outputId": "31b1ff00-eb68-40d7-b96e-681ffdefe3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what store offers rags? :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity: 0.6123305785907626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Augmented Input\n",
        "augmented_input=query+ \" \"+ best_matching_record\n"
      ],
      "metadata": {
        "id": "JNvohk3xg1Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP3MAZEYg6EZ",
        "outputId": "63ed063b-5a34-426f-c38b-42956f09c71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "what store offers rags? A RAG vector store is a database or dataset that\n",
            "contains vectorized data points.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generation\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0pb344g8EW",
        "outputId": "9bd0f00a-519a-4058-f2bd-9601524b38fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------------\n",
            "To address your query about where to find \"rags,\" there are several places where\n",
            "you can typically find cleaning rags or cloths:  1. **Hardware Stores**: Stores\n",
            "like **Home Depot**, **Lowe's**, or **ACE Hardware** often have a variety of\n",
            "cleaning supplies including rags.  2. **Big Box Retailers**:     - **Walmart**\n",
            "and **Target** usually have a section for cleaning supplies where you can find\n",
            "rags or microfiber cloths.  3. **Grocery Stores**: Many supermarkets like\n",
            "**Kroger**, **Safeway**, or **Whole Foods** carry basic cleaning supplies,\n",
            "including rags.  4. **Dollar Stores**:     - **Dollar Tree**, **Dollar\n",
            "General**, or **Family Dollar** often sell rags or cleaning cloths at a lower\n",
            "cost.  5. **Automotive Parts Stores**: If you're looking for heavy-duty or shop\n",
            "rags, places like **AutoZone**, **Advance Auto Parts**, or **O'Reilly Auto\n",
            "Parts** would have them.  6. **Online Retailers**:    - **Amazon** offers a vast\n",
            "selection of rags in different materials and sizes.    - **eBay** might have\n",
            "bulk options or unique finds.    - **Walmart.com** and **Target.com** for online\n",
            "shopping options.  7. **Specialty Cleaning Supply Stores**: These might offer\n",
            "higher quality or specialized cleaning cloths.  8. **Thrift Stores or Second-\n",
            "Hand Shops**: Sometimes you can find old cloths or t-shirts that can be\n",
            "repurposed as rags.  If you're looking for RAG (Retrieval-Augmented Generation)\n",
            "vector stores or databases, here are some contexts where you might find or\n",
            "implement them:  - **Databases**:    - **Pinecone**, **Weaviate**, **Milvus**,\n",
            "or **Faiss** are examples of systems designed for vector similarity search,\n",
            "which can be used to implement RAG systems.  - **Cloud Services**:    - **AWS**,\n",
            "**Google Cloud**, and **Microsoft Azure** provide services like **Amazon\n",
            "Elasticsearch** or **Google Cloud Search** which can be configured for vector\n",
            "search capabilities.  - **Open Source Projects**:    - Platforms like **GitHub**\n",
            "might host open-source projects for RAG implementations or vector databases.\n",
            "Remember, when looking for physical rags, consider the material, absorbency, and\n",
            "durability depending on your cleaning needs. For RAG vector stores, think about\n",
            "the scalability, performance, and the specific use case for which you need to\n",
            "store and retrieve vectorized data.\n",
            "---------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfyPscW-hD0p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}